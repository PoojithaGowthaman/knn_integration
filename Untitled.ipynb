{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subpackage_1.KNN_data_collection as knn\n",
    "import subpackage_1.generate_predictions as gp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created KNN classifier with k=2!\n",
      "Dataset successfully loaded!\n",
      "Successfully completed train/test split!\n",
      "Training set: 90 samples\n",
      "Test set: 60 samples\n"
     ]
    }
   ],
   "source": [
    "classification_model=knn.KNN('classifier',2)\n",
    "classification_model.load_csv('Iris.csv','Species')\n",
    "classification_model.train_test_split(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Learnings/workspace/Labs/knn/subpackage_1/generate_predictions.py:27: UserWarning: Warning: A tie has occurred (top two classes in K nearest neighbors have the same number of occurances). Classification depends on the order of the training data.\n",
      "  warnings.warn('Warning: A tie has occurred (top two classes in K nearest neighbors have the same number of occurances). Classification depends on the order of the training data.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_train = gp.generate_predictions(classification_model,[[1,2,3,4], [5,6,7,8]],'train')\n",
    "res_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_accuracy(actual, predicted): # for classifer\n",
    "    \"\"\"Model accuracy for Classification\"\"\"\n",
    "    if np.mean(np.array(predicted)) == np.mean(np.array(actual)):\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    print(\"Prediction Output: (1: Success, 0:Incorrect prediction)\", result) \n",
    "\n",
    "def model_misclassification(actual, predicted): #for classifer\n",
    "        misclassification_rate = 0\n",
    "        total_size = np.size(np.array(actual))\n",
    "        missclassify = np.mean(np.array(predicted)) != np.mean(np.array(actual))\n",
    "        misclassification_rate = (total_size - missclassify)/total_size\n",
    "        print('Misclassification Rate:',misclassification_rate)\n",
    "        \n",
    "            \n",
    "def model_rmse(actual, predicted): # for regressor\n",
    "    total_size = np.size(actual)\n",
    "    rmse = 0\n",
    "    rmse = np.sqrt(np.mean(predicted - actual)**2)\n",
    "    return rmse\n",
    "    \n",
    "def model_mape(actual, predicted): # for regressor\n",
    "    total_size = np.size(actual)\n",
    "    mape = 0\n",
    "    if knn_type == 'regressor':\n",
    "        mape = (np.sum(np.abs(actual - predicted)/actual)/total_size)* 100\n",
    "    return mape\n",
    " \n",
    "def assesment_metrics(knn_type, train_obs, test_obs):\n",
    "    test_accuracy = 0\n",
    "    test_missclassification =0\n",
    "    test_mape = 0\n",
    "    test_rmse = 0\n",
    "    \n",
    "    if knn_type == 'regressor':\n",
    "        train_result = gp.generate_predictions(regression_model, [train_obs, test_obs], 'train').astype(float)\n",
    "        test_result = gp.generate_predictions(regression_model, [train_obs, test_obs], 'all').astype(float)\n",
    "        test_rmse = model_rmse(test_result, train_result)\n",
    "        test_mape = model_mape(test_result,train_result)\n",
    "        \n",
    "    elif knn_type == 'classifier':\n",
    "        train_result = gp.generate_predictions(classification_model, [train_obs, test_obs], 'train')\n",
    "        test_result = gp.generate_predictions(classification_model, [train_obs, test_obs], 'all')\n",
    "        \n",
    "        test_accuracy = model_accuracy(test_result,train_result)\n",
    "        test_missclassification = model_misclassification(test_result,train_result)\n",
    "   \n",
    "    print('Accuracy of the Classifier model :', test_accuracy )\n",
    "    print('Misclassification of Classifier model : ',test_missclassification)    \n",
    "    print('RSME of regressor :', test_rmse)\n",
    "    print('MAPE of regressor : ',test_mape)\n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Classifier model : 0\n",
      "Misclassification of Classifier model :  0\n",
      "RSME of regressor : 0\n",
      "MAPE of regressor :  0\n"
     ]
    }
   ],
   "source": [
    "assesment_metrics('classifer', [3,4,5,7], [5,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Output: (1: Success, 0:Incorrect prediction) 0\n"
     ]
    }
   ],
   "source": [
    "model_accuracy([3,4,5,7], [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
